{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d3269d-6158-4b6f-9563-b3441570572a",
   "metadata": {},
   "source": [
    "### Scikit Learn Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9aae63-2c65-4e35-bb5d-986c4d2bdef2",
   "metadata": {},
   "source": [
    "#### Estimator 이해 및 fit(), predict() 메서드\n",
    "사이킷런은 ML 모델 학습을 위해서 fit()을, 학습된 모델의 예측을 위해 predict() 메서드를 제공합니다.</br>\n",
    "지도학습의 주요 두 축인 분류(Classification)과 회귀(Regression)의 다양한 알고리즘을 구현한 모든 사이킷런 클래스는</br>\n",
    "fit()과 predict()만을 이요해 간단하게 학습과 예측 결과를 반환합니다.</br>\n",
    "</br>\n",
    "분류 알고리즘을 구현한 클래스를 Classifier, 회귀 알고리즘을 구현한 클래스를 Regressor로 지칭합니다.</br>\n",
    "사이킷런은 매우 많은 유형의 Classifier와 Regressor를 제공하고 이 둘을 합쳐 Estimator 클래스라고 부릅니다.</br>\n",
    "Estimator 클래스는 fit()과 predict()를 내부에서 구현하고 있습니다.</br>\n",
    "</br>\n",
    "evaluation 함수(ex.cross_cal_score()), GridSearchCV와 같은 하이퍼 파라미터 튜닝을 지원하는 클래스의 경우 이 Estimator를 인자로 받습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a77d24-6bd6-4d12-9a5f-12cdf76b4e88",
   "metadata": {},
   "source": [
    "### 사이킷런의 주요 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4932ea0f-5139-4dc2-a569-d814e8e4ee93",
   "metadata": {},
   "source": [
    "* 예제 데이터: sklearn.datasets\n",
    "* 피처처리: sklearn.processing, sklearn.feature_selection, sklearn.feature_extraction\n",
    "* 피처처리&차원축소: sklearn.decompostion\n",
    "* 데이터 분리, 검증 & 파라미터 튜닝: sklearn.model_selection\n",
    "* 평가: sklearn.metrics\n",
    "* Ml 알고리즘:\n",
    "        sklearn.ensemble -앙상블 알고리즘 제공(렌덤 포레스트, 에이다부스트, 그래디언트 부스트)\n",
    "        sklearn.linear_model -선형회귀, 릿지(Ridge), 라쏘(Lasso), 및 로지스틱 회귀 등 회귀 관련 알고리즘을 지원.\n",
    "        sklearn.naive_bayes -나이브 베이즈 알고리즘 제공.\n",
    "        sklearn.neighbors -최근접 이웃 알고리즘 제공,K-NN 등.\n",
    "        sklearn.svm: Support Vector Machine.\n",
    "        sklearn.tree: 의사결정 트리 알고리즘 제공.\n",
    "        sklearn.cluster: 비지도 클러스터링 알고리즘 제공.\n",
    "* 유틸리티: sklearn.pipeline: 피처 처리 증의 변환과 ML 알고리즘 학습, 예측 등을 함께 묶어서 실행할 수 있는 유틸리티 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4ae20-6e28-449a-a487-360d9aa30c7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 내장된 에제 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5441741-5439-4eb5-9b25-7b12a435b0dd",
   "metadata": {},
   "source": [
    "사이킷런의 데이터 세트는 일반적으로 딕셔너리 형태로 되어 있습니다. </br>\n",
    "딕셔너리의 키는 보통 data, target_name, feature_name, DESCR로 구성되어 있습니다.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e049e761-f536-467a-aae9-1c2074b7ace6",
   "metadata": {},
   "source": [
    "* data: 피처와 데이터 세트를 가리킵니다\n",
    "* target: 분류 시 레이블 값, 회귀일 때는 숫자 결괏값 데이터 세트입니다.\n",
    "* target_names는 개별 레이블의 이름을 나타냅니다.\n",
    "* DESCR은 데이터 세트에 대한 설명과 각 피처의 설명을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddede35e-d8f2-4055-8c2e-27be690cccec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469105e-f0d7-44a2-9723-6f35e660bdee",
   "metadata": {},
   "source": [
    "Bunch 클래스는 파이썬 딕셔너리 자료형과 유사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3ae987-01e6-4b27-8f53-338da5a6ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "# load_iris() dataset의 key값 확인\n",
    "keys = iris_data.keys()\n",
    "print('붓꽃 데이터 세트의 키들:', keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b372998f-b49a-49aa-b655-39ccc61d050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris 데이터의 feature_name:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "iris 데이터의 target_names:  ['setosa' 'versicolor' 'virginica']\n",
      "iris 데이터의 target:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print('iris 데이터의 feature_name: ',iris_data.feature_names)\n",
    "#print('iris 데이터의 data: ', iris_data['data'])\n",
    "print('iris 데이터의 target_names: ', iris_data.target_names)\n",
    "print('iris 데이터의 target: ', iris_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3241f3a8-96ae-409d-9653-cf2f5d676bdf",
   "metadata": {},
   "source": [
    "#### Model Selection 모듈 소개\n",
    "사이킷런의 model_selection 모듈은 학습 데이터와 테스트 데이터 세트를 분리하거나 교차 검증 분리할 및 평가, 그리고 Estimator의 하이퍼 파라미터를 튜닝하기 위한 다양한 함수와 클래스를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324628ea-b101-4480-8450-30301aac8cc2",
   "metadata": {},
   "source": [
    "#### 04.학습/테스트 데이터 세트 분리 - train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569f6f82-46f8-4912-b910-5705d4697579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \\\n",
    "                                               test_size = 0.3, random_state = 121)\n",
    "\n",
    "\n",
    "# train_data = iris.data\n",
    "# train_label = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed8a738-3560-4287-9b94-d32a45136ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44f582-da1b-4a22-aa47-6425edd52f17",
   "metadata": {},
   "source": [
    "#### 교차 검증\n",
    " 예측 성능을 평가하기 위한 별도의 테스트용 데이터를 사용하는 경우 과적합(Overfitting)에 취약한 약점을 가질 수 있습니다. </br>\n",
    "과적합은 모델이 특정 학습데이터에만 과도하게 최적화 되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 것을 말합니다.</br>\n",
    "이를 해결하기 이해 교차검증을 이용해 더 다양한 학습과 평가를 수행합니다.</br>\n",
    "데부분의 ML 모델의 성능 평가는 교차 검증 기반으로 1차 평가를 한 뒤에 최종적으로 테스트 데이터 세트에 적용해 평가하는 프로세스입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f3e01f-3773-4a67-a2ae-c19d254a821c",
   "metadata": {},
   "source": [
    "#### K폴드 교차 검증\n",
    "K 폴드 교차 검증은 가장 보편적으로 사용되는 교차 검증 기법입니다. 먼저 K 개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복쩍으로 수행하는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9446ac4d-eefe-47cd-9236-c4d42df502c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런에서는 K폴드 교차 검증 프로세스를 구현하기 위해 KFold와 StratifiedKFold 클래스를 제공합니다.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb8553a-6f62-495c-a82f-bef36143e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "# 5개의 폳드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold = KFold(n_splits = 5)\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기:', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8837858f-3a0e-40b3-931c-18f5903de9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도:1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도:0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도:0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도:0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도:0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "# 5개의 폴드 세트를 생성하는 KFold 객체의 split()을 호출해 교차 검증 수행 시마다 학습과 검증을 반복해 예측 정확도를 측정합니다.\n",
    "n_iter = 0\n",
    "\n",
    "#KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    #kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    n_iter += 1\n",
    "    #반복 시마다 정확도 측정\n",
    "\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print('\\n#{0} 교차 검증 정확도:{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4cbfbc-ad9e-453e-9b59-ddd5de6e45a7",
   "metadata": {},
   "source": [
    "5번 교차 검증 결과 평균 검증 정확도는 0.9 입니다. 그리고 교차 검증 시마다 검증 세트의 인덱스가 달라짐을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c318d16f-158c-41b6-b5a6-109cfc1dce83",
   "metadata": {},
   "source": [
    "#### Stratified K Fold\n",
    " Stratified K Fold는 불균형한 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식입니다. 불균형한 분포도를 가진 레이블 데이터 집합은 특정레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것을 말합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aa3dedf-135b-4caf-ab0c-6fd6be52f805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9f22a6-81df-4e6c-b7b0-4b0a64e65585",
   "metadata": {},
   "source": [
    "레이블 값은 0, 1, 2 값 모두 50개로 동일합니다. 즉, Setosa, Versicolor, Virginica 품종 모두 50개 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec03688-6183-4d30-abdc-305072806e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "##교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "##교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3개의 폴드 세트를 KFold로 생성하고, 각 교차 검증 시마다 생성되는 학습/검증 레이블 데이터 값의 분포도를 확인합니다.\n",
    "kfold = KFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('##교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e85c50-9a54-4126-bd3d-6ae22a912dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 교차검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "### 교차검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "### 교차검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 동일한 데이터 분할을 StratifiedKfold로 수행하고 학습 검증 레이블 데이터의 분포도를 확인합니다.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    print('### 교차검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75db4b6-d672-4d8c-91c6-adec71ea66e4",
   "metadata": {},
   "source": [
    "출력 겨과를 보면 학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당되었음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9530380-22d8-4144-b8c6-70a723804891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1.교차 검증 정확도:0.98, 학습데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "#2.교차 검증 정확도:0.94, 학습데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "#3.교차 검증 정확도:0.98, 학습데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "# StratifiedKFold를 이용해 데이터 분리합니다.\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "# StratifiedKFold의 split() 호출시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    #split()으로 반환된 인덱스를 이요해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index],features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    #반복 시마다 정확도 측정\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print('\\n#{0}.교차 검증 정확도:{1}, 학습데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32995c47-baf4-49c5-a41a-61fe6591961c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증별 정확도 및 평균 정확도 계산\n",
    "\n",
    "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy,4))\n",
    "print('## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ebf00-a403-42b1-939e-0adcbb8ec4fd",
   "metadata": {},
   "source": [
    "일반적으로 분류(Classification)에서의 교차검증은 Kfold가 아니라 Stratified KFold로 분할되어야 합니다.</br>\n",
    "회귀(Regression)에서는 Stratified K Fold를 지원하지 않습니다</br>\n",
    "회귀의 결정값은 이산값 형태의 레이블이 아니라 연속된 숫자의 값이기 때문에 결정값 별로 분포를 정하는 의미가 없기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342ef253-78ca-4f6d-8904-c25fef87aba8",
   "metadata": {},
   "source": [
    "#### cross_val_score() - 교차검증을 보다 간편하게\n",
    "cross_val_score(estimator, X, y= None, scoring= None, cv= None, n_jobs= 1, verbose=0, fit_params= None, pre_dispatch= '2*n_jobs')</br>\n",
    "이중 estimator, X, y, scoring, cv가 주요 파라미터입니다.\n",
    "* estimator, Classifier 또는 Regression를 의미합니다.\n",
    "* X는 피처 데이터세트, y는 레이블 데이터 세트\n",
    "* scoring은 예측 성능 평가 지표를 기술\n",
    "* cv는 교차 검증 폴드 수를 의미합니다.\n",
    "\n",
    "cross_val_score() 수행 후 반환 값은 scoring 파라미터로 지정된 성능 지표 측정갑슬 배열 형태로 반환합니다.</br>\n",
    "cross_val_score()는 classifier가 입력되면 StratifiedKFold, Regression은 KFold 방식으로 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10f8e209-528f-4429-b6cd-ff312aaf6410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state= 156)\n",
    "\n",
    "data= iris_data.data\n",
    "label= iris_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24766c0f-68e8-44aa-a1b8-3800a9d08b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
    "\n",
    "scores = cross_val_score(dt_clf, data, label, scoring= 'accuracy', cv= 3)\n",
    "print('교차 검증별 정확도:', np.round(scores, 4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a72ed-20bc-48eb-b45b-7ff0dfc174d8",
   "metadata": {},
   "source": [
    "cross_val_score()은 cv로 지정된 횟수만큼 scoring 파라미터로 지정된 평가 지표로 평가 결괏값을 배열로 변환합니다. 이를 평균해 평가 수치로 사용합니다.</br>\n",
    "cross_val_score API는 내부에서 Estimator를 학습(fit), 예측(predict), 평가(evaluation)시켜주므로 간단하게 교차검증을 수행할 수 있습니다.</br>\n",
    "</br>\n",
    "비슷한 API로 cross_validate()가 있습니다. cross_val_score()는 단 하나의 평가 지표만 가능하지만 cross_validate()는 여러 개의 평가 지표를 반환할 수 있습니다.</br>\n",
    "또한 학습 데이터에 대한 성능 평가가 지표와 수행 시간도 같이 제공합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
